<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/html">
<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG">
    <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
    <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
    <meta property="og:url" content="URL OF THE WEBSITE"/>
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="630"/>


    <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
    <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>Academic Project Page</title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link href="https://fonts.cdnfonts.com/css/lucida-unicode-calligraphy" rel="stylesheet">
    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>

    <style>
        .mathcal {
            font-family: 'Lucida Unicode Calligraphy', sans-serif;
        }
    </style>
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">Arbitrary-Scale Image Generation and Upsampling using
                        Latent Diffusion Model and Implicit Neural Decoder</h1>
                    <div class="is-size-5 publication-authors">
                        <!-- Paper authors -->
                        <span class="author-block">
                <a href="/" target="_blank">Jinseok Kim</a><sup>1, 3</sup>,</span>
                        <span class="author-block">
                  <a href="https://sites.google.com/view/tkkim" target="_blank">Tae-Kyun Kim</a><sup>1, 2</sup>,</span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block"><sup>1</sup>KAIST, &nbsp;&nbsp;<sup>2</sup>Imperial College London, &nbsp;&nbsp;<sup>3</sup>AI Lab, LG Electronics<br><b>CVPR 2024</b></span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- Arxiv PDF link -->
                            <span class="link-block">
                        <a href="https://arxiv.org/pdf/2403.10255.pdf" target="_blank"
                           class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                            <!-- ArXiv abstract Link -->
                            <span class="link-block">
                    <a href="https://arxiv.org/abs/2403.10255" target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                    </a>
                  </span>

                            <!-- Github link -->
                            <span class="link-block">
                    <a href="https://github.com/zhenshij/arbitrary-scale-diffusion" target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
    <div class="container is-max-desktop">
        <div class="hero-body">
            <img src="static/images/teaser.png"/>
        </div>
    </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        Super-resolution (SR) and image generation are important tasks in computer vision and are widely
                        adopted in real-world applications.
                        Most existing methods, however, generate images only at fixed-scale magnification and suffer
                        from over-smoothing and artifacts.
                        Additionally, they do not offer enough diversity of output images nor image consistency at
                        different scales.
                        Most relevant work applied Implicit Neural Representation (INR) to the denoising diffusion model
                        to obtain continuous-resolution yet diverse and high-quality SR results.
                        Since this model operates in the image space, the larger the resolution of image is produced,
                        the more memory and inference time is required, and it also does not maintain scale-specific
                        consistency.
                        We propose a novel pipeline that can super-resolve an input image or generate from a random
                        noise a novel image at arbitrary scales. The method consists of a pre-trained auto-encoder, a
                        latent diffusion model, and an implicit neural decoder, and their learning strategies.
                        The proposed method adopts diffusion processes in a latent space, thus efficient, yet aligned
                        with output image space decoded by MLPs at arbitrary scales.
                        More specifically, our arbitrary-scale decoder is designed by the symmetric decoder w/o
                        up-scaling from the pre-trained auto-encoder, and Local Implicit Image Function (LIIF) in
                        series. The latent diffusion process is learnt by the denoising and the alignment losses
                        jointly. Errors in output images are backpropagated via the fixed decoder, improving the quality
                        of output images.
                        In the extensive experiments using multiple public benchmarks on the two tasks i.e. image
                        super-resolution and novel image generation at arbitrary scales, the proposed method outperforms
                        relevant methods in metrics of image quality, diversity and scale consistency. It is
                        significantly better than the relevant prior-art in the inference speed and memory usage.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End paper abstract -->

<!-- Image Generation -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <h2 class="title is-3">Image Generation</h2>
            <div id="results-carousel" class="carousel results-carousel">
                <div class="item">
                    <!-- Your image here -->
                    <img src="static/images/div_face.png" alt="MY ALT TEXT"/>
                    <h2 class="subtitle has-text-centered">
                        Visual results of image generation on the FFHQ datasets.
                    </h2>
                </div>
                <div class="item">
                    <!-- Your image here -->
                    <img src="static/images/div_church.png" alt="MY ALT TEXT"/>
                    <h2 class="subtitle has-text-centered">
                        Visual results of image generation on the LSUN Church datasets.
                    </h2>
                </div>
                <div class="item">
                    <!-- Your image here -->
                    <img src="static/images/div_bedroom.png" alt="MY ALT TEXT"/>
                    <h2 class="subtitle has-text-centered">
                        Visual results of image generation on the LSUN Bedroom datasets.
                    </h2>
                </div>
                <div class="item">
                    <!-- Your image here -->
                    <img src="static/images/gen_face.png" alt="MY ALT TEXT"/>
                    <h2 class="subtitle has-text-centered">
                        Scale consistency results of image generation on the FFHQ datasets.
                    </h2>
                </div>
                <div class="item">
                    <!-- Your image here -->
                    <img src="static/images/gen_church.png" alt="MY ALT TEXT"/>
                    <h2 class="subtitle has-text-centered">
                        Scale consistency results of image generation on the LSUN Church datasets.
                    </h2>
                </div>
                <div class="item">
                    <!-- Your image here -->
                    <img src="static/images/gen_bedroom.png" alt="MY ALT TEXT"/>
                    <h2 class="subtitle has-text-centered">
                        Scale consistency results of image generation on the LSUN Bedroom datasets.
                    </h2>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End Image Generation -->


<!-- Super-Resolution -->
<section class="hero is-small is-light">
    <div class="hero-body">
        <div class="container">
            <h2 class="title is-3">Super-Resolution</h2>
            <div id="sr-results-carousel" class="carousel results-carousel">
                <div class="item">
                    <!-- Your image here -->
                    <img src="static/images/sr_compare.png" alt="MY ALT TEXT"/>
                    <h2 class="subtitle has-text-centered">
                        Qualitative comparisons with arbitrary-scale upsampling methods upsampling on CelebA-HQ datasets.
                    </h2>
                </div>
                <div class="item">
                    <!-- Your image here -->
                    <img src="static/images/sr_compare2.png" alt="MY ALT TEXT"/>
                    <h2 class="subtitle has-text-centered">
                        Qualitative comparisons with arbitrary-scale upsampling methods on LSUN Tower datasets.
                    </h2>
                </div>
                <div class="item">
                    <!-- Your image here -->
                    <img src="static/images/sr_compare3.png" alt="MY ALT TEXT"/>
                    <h2 class="subtitle has-text-centered">
                        Qualitative comparisons with arbitrary-scale upsampling methods on DIV2K (in-the-wild) datasets.
                    </h2>
                </div>
                <div class="item">
                    <!-- Your image here -->
                    <img src="static/images/sr_scale_consistency.png" alt="MY ALT TEXT"/>
                    <h2 class="subtitle has-text-centered">
                        Scale consistency results of arbitrary-scale upsampling.
                    </h2>
                    <img src="static/images/sr_scale_consistency2.png" alt="MY ALT TEXT"/>
                    <h2 class="subtitle has-text-centered">
                         Scale consistency Comparisons with arbitrary-scale upsampling methods.
                    </h2>
                </div>
                <div class="item">
                    <!-- Your image here -->
                    <img src="static/images/sr_diversity.png" alt="MY ALT TEXT"/>
                    <h2 class="subtitle has-text-centered">
                        Visualization of result diversity in super-resolution tasks.
                    </h2>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End Super-Resolution -->


<!-- Model Architecture -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <h2 class="title is-3">Model Architecture</h2>
            <div class="content has-text-justified">
                <p>
                    We propose a simple architecture that combines the LDM and LIIF decoder for both arbitrary-scale SR
                    and image generation. An auto-encoder consisting of an encoder and a symmetric decoder w/o
                    upsampling is pre-trained. Our implicit neural decoder combines the convolutional decoder from the
                    auto-encoder and MLP-based decoder, that can map to arbitrary-scale output images.
                </p>
            </div>
            <div class="item">
                <!-- Your image here -->
                <img src="static/images/architecture.png" alt="Model Architecture"/>
                <p class="content has-text-justified">
                    <b>Upper Part:</b> Overall process of proposed networks. <span style="color:red;">Red line</span> is
                    a super-resolution process, and <span style="color:blue;">Blue line</span> is a generation process.
                    <b>Lower Left Part:</b> Detail architecture of Implicit Neural Decoder. It contains a series of
                    auto-decoder <span class="mathcal">D<sub>φ</sub></span> and a neural decoding function <span
                        class="mathcal">f<sub>θ</sub></span>. <b>Lower Right Part:</b> Pipeline of two-stage alignment
                    process.
                </p>
            </div>
        </div>
    </div>
</section>
<!-- End Model Architecture -->


<!-- Paper poster -->
<section class="hero is-small is-light">
    <div class="hero-body">
        <div class="container">
            <h2 class="title">Poster</h2>
            <img src="static/images/poster.png" alt="Poster"/>
        </div>
    </div>
</section>
<!--End paper poster -->


<!--BibTex citation -->
<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@inproceedings{kim2024arbitraryscale,
      title={Arbitrary-Scale Image Generation and Upsampling using Latent Diffusion Model and Implicit Neural Decoder},
      author={Kim, Jinseok and Kim, Tae-Kyun},
      booktitle={CVPR},
      year={2024}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">

                    <p>
                        This page was built using the <a
                            href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic
                        Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io"
                                                                                target="_blank">Nerfies</a> project
                        page.<br> This website is licensed under a <a rel="license"
                                                                      href="http://creativecommons.org/licenses/by-sa/4.0/"
                                                                      target="_blank">Creative
                        Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>

                </div>
            </div>
        </div>
    </div>
</footer>

<!-- Statcounter tracking code -->

<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->

</body>
</html>
